# ğŸ§ª PetStore API Tests

Automated testing of the public **Swagger PetStore** REST API using **PyTest**, **Requests**, and **Allure**.

---

## ğŸ¯ Project Goals
- Validate CRUD operations for **User**, **Pet**, and **Store** entities.
- Demonstrate the use of fixtures, parametrization, and a lightweight API client wrapper.
- Set up **Allure** reporting and enable parallel test execution.

---

## âš™ï¸ Tech Stack
- **Python 3.11+**
- **PyTest**
- **Requests**
- **Allure-PyTest**
- **pytest-xdist** (parallel runs)
- **pytest-rerunfailures** (retry flaky tests)
- **Makefile** (common commands)

---

## ğŸ“ Project Structure
```
PetStoreProject/
â”‚
â”œâ”€â”€ tests/                          # Test suite
â”‚   â”œâ”€â”€ test_user_crud.py           # User CRUD
â”‚   â”œâ”€â”€ test_store_order.py         # Store orders
â”‚   â”œâ”€â”€ test_store_inventory.py     # Store inventory
â”‚   â”œâ”€â”€ test_pet_crud.py            # Pet CRUD
â”‚   â””â”€â”€ test_pet_find_and_upload.py # Pet image upload & find
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ api_client.py               # API client wrapper
â”‚
â”œâ”€â”€ pytest.ini                      # PyTest configuration
â”œâ”€â”€ conftest.py                     # Shared fixtures & helpers
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ Makefile                        # Make targets for local runs
â”œâ”€â”€ .gitignore                      # Git ignore rules
â””â”€â”€ README.md                       # Documentation
```

---

## âœ… Test Coverage

| Module | Scenarios | Case Types |
|---|---|---|
| **Pet** | create, read, update, delete, image upload | valid & invalid CRUD |
| **User** | create, read, update, delete, login/logout | valid & invalid data |
| **Store** | create order, delete order, check inventory | valid & invalid IDs |

**Total tests:** 27  
**Breakdown:**
- âœ… Valid scenarios â€” 17
- âš ï¸ Invalid scenarios â€” 10

---

## ğŸ§° Test Diagnostics
Useful commands to verify that PyTest correctly discovers all tests and parametrized nodes.

### ğŸ”¹ List all collected test nodes
Save all collected nodes (including parametrized ones) to `now.txt`:
```bash
pytest --collect-only -q > now.txt
```

### ğŸ”¹ Per-file summary (how many tests per file)
```bash
awk -F'::' '{print $1}' now.txt | sort | uniq -c
```

### ğŸ”¹ Inspect tests inside a specific file
```bash
pytest tests/test_store_order.py --collect-only -q
```

---

## ğŸ§© Approaches Used

### ğŸ”¹ Fixtures
Used for:
- creating and cleaning up test users, pets, and orders;
- preparing data before test execution;
- repeated GET checks with waiting (`get_with_retry`);
- automatic resource cleanup after tests (`cleanup`).

### ğŸ”¹ Parametrize
Applied to:
- test different input combinations (e.g., `userStatus`, `petStatus`, `orderId`);
- validate APIs with valid and invalid parameters;
- reduce duplication while increasing coverage.

> ğŸ’¡ This keeps the code **flexible, readable, and maintainable**â€”adding scenarios often means extending parameters instead of duplicating tests.

### ğŸ”¹ Smoke & Regression marks
- `@pytest.mark.smoke` â€” **critical flows** (API availability & core operations)
- `@pytest.mark.regression` â€” **deep stability checks** after changes

### ğŸ”¹ Flaky tests
To handle unstable responses from the public PetStore API:
```python
@pytest.mark.flaky(reruns=2, reruns_delay=1)
```
This ensures:
- up to **2 automatic reruns** with a 1â€‘second delay;
- more stable CI/CD pipelines despite transient issues;
- Allure keeps visibility with the â€œFlakyâ€ label.

---

## ğŸš€ Local Setup & Run
> Requirements: **Python 3.11+**, **Allure CLI** installed

### 1ï¸âƒ£ Go to the project root
Make sure you are where `pytest.ini`, `requirements.txt`, and `Makefile` are located.

### 2ï¸âƒ£ Create a virtual environment
**macOS / Linux**
```bash
python3 -m venv .venv
source .venv/bin/activate
```
**Windows**
```powershell
python -m venv .venv
.venv\Scripts\Activate.ps1
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Run tests
```bash
pytest -v
```
Parallel execution:
```bash
pytest -v -n auto
```

### 5ï¸âƒ£ Generate Allure report
```bash
pytest --alluredir=allure-results
allure serve allure-results
```
If `allure` is not found:
- macOS â†’ `brew install allure`
- Windows â†’ `choco install allure` or `scoop install allure`

---

## ğŸ“Š Reporting
After a test run, open the report:
```bash
allure serve allure-results
```
Allure provides an interactive report with:
- **Suites** â€” test suites by files
- **Behaviors** â€” grouping by features (`@allure.feature`, `@allure.story`)
- **Graphs / Timeline** â€” trends and execution time
- **Attachments** â€” JSON responses, logs, and status codes

Each run can start clean when using the Makefile target: **`make report`**.

---

## ğŸ§  Makefile Commands
- **`make smoke`** â€” run smoke tests (`MARK=smoke`) and open the report
- **`make regression`** â€” run regression tests (`MARK=regression`)
- **`make report`** â€” clean, run tests, generate Allure report, and open it
- **`make clean`** â€” remove `allure-results` and `allure-report`
- **`make open-report`** â€” open an already generated Allure report

---

## ğŸ‘©â€ğŸ’» Author
**Irina Weitzman**  
QA Engineer | Python | API Automation Testing  
ğŸ“« GitHub: **iwtzmn**